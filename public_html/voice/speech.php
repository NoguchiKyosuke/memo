<?php
require_once '../includes/head.php';
require_once '../includes/common.php';
require_once '../includes/ad.php';

$title = 'éŸ³å£°è§£æã¨æ©Ÿæ¢°å­¦ç¿’ã®ç ”ç©¶ãƒ¡ãƒ¢ - ãƒ¡ãƒ¢å¸³';
$description = 'éŸ³å£°è§£æã¨æ©Ÿæ¢°å­¦ç¿’ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢ã€‚MFCCã‚„DTWã€z-scoreã€Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä½¿ã„æ–¹ãªã©ã€éŸ³å£°å‡¦ç†æŠ€è¡“ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚';
$keywords = 'éŸ³å£°è§£æ,æ©Ÿæ¢°å­¦ç¿’,MFCC,DTW,z-score,Python,librosa,éŸ³å£°å‡¦ç†,ã‚¢ã‚¤ãƒŒèª,ç ”ç©¶ãƒ¡ãƒ¢';

renderHead($title, $description, $keywords);
?>
<body>
<?php renderNavigation('speech'); ?>

<!-- MathJax for mathematical expressions -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
    }
};

function collapseAllCodeBlocks() {
    document.querySelectorAll('pre#pythonCode').forEach(function(pre) {
        pre.classList.add('collapsed');
        const container = pre.parentElement;
        if (container) {
            const tableWrap = container.previousElementSibling;
            if (tableWrap && tableWrap.classList && tableWrap.classList.contains('md-table-wrap')) {
                tableWrap.classList.add('collapsed');
            }
        }
    });
}

// åˆæœŸåŒ–
document.addEventListener('DOMContentLoaded', function() {
    collapseAllCodeBlocks();
});
</script>

<style>
html{-webkit-text-size-adjust:100%;}
body{font-family:system-ui,Helvetica,Arial,sans-serif;line-height:1.6;word-break:break-word;color:#333333;}
h1{margin:.2rem 0 1rem;font-size:2rem;}
h2{margin-top:1.8rem;font-size:1.3rem;border-bottom:2px solid #ccc;padding-bottom:.25rem;}
h3{margin-top:1.1rem;font-size:1.1rem;}
p{line-height:1.7;}
ul{padding-left:1.3rem;}
li{color:#333333;margin-bottom:0.3rem;}
a{color:#0066cc;text-decoration:none;}
a:hover{text-decoration:underline;color:#004499;}
@media (max-width:640px){
    body{margin:1.2rem auto;padding:0 .9rem;}
    h1{font-size:1.7rem;}
    h2{font-size:1.2rem;}
    h3{font-size:1.02rem;}
}
#pythonCode {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #0066cc;
    overflow-x: auto;
    font-size: 0.9rem;
    line-height: 1.4;
    margin: 1.5rem 0;
    color: #2c3e50;
}
div[style*="position: relative"] {
    position: relative !important;
}

.research-section {
    margin: 2rem 0;
    padding: 1.5rem;
    background-color: #f9f9f9;
    border-radius: 8px;
    border-left: 4px solid #036;
}

.research-item {
    margin: 1rem 0;
    padding: 1rem;
    background-color: white;
    border-radius: 6px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.research-item h3 {
    color: #036;
    margin-top: 0;
}

</style>

<main class="container fade-in" style="max-width:880px;margin:0 auto;padding:2.2rem 0 3rem;">
  <article>
    <header>
      <h1>éŸ³å£°è§£æã¨æ©Ÿæ¢°å­¦ç¿’ã®ç ”ç©¶ãƒ¡ãƒ¢ <span class="update-info">(<?php echo date('Yå¹´mæœˆdæ—¥æ›´æ–°', filemtime(__FILE__)); ?>)</span></h1>
    </header>
    
    <?php renderAdBanner(); ?>

    <section><h2>2025/9/9</h2>
    <h3>ã‚¢ã‚¤ãƒŒèªã®å‹‰å¼·</h3>
    <h4>z-scoreã¨ã¯</h4>
    <p>z-scoreã¯æ¨™æº–å¾—ç‚¹ã®ã“ã¨ã€‚åˆ¥å"standard score"ã¨ã‚‚è¨€ã†ã€‚</p>
    <p>z-scoreã®å¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¡¨ã•ã‚Œã‚‹ã€‚</p>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$z = \frac{X - \mu}{\sigma}$$
    </div>
    <p>ã“ã“ã§ã€$X$ã¯å„ãƒ‡ãƒ¼ã‚¿ã®å€¤ã€$\mu$ã¯å¹³å‡ã€$\sigma$ã¯æ¨™æº–åå·®ã‚’è¡¨ã™ã€‚</p>
    <p>z-scoreãŒ0ã®éš›ã¯<br/>
        ãƒ‡ãƒ¼ã‚¿ã®å€¤ãŒå¹³å‡ã¨ç­‰ã—ã„ã€‚<br/>
        æ­£ã®å€¤ã®éš›ã¯ãƒ‡ãƒ¼ã‚¿ã®å€¤ãŒå¹³å‡ã‚ˆã‚Šã‚‚é«˜ã„ã€‚<br/>
        è² ã®å€¤ã®éš›ã¯ãƒ‡ãƒ¼ã‚¿ã®å€¤ãŒå¹³å‡ã‚ˆã‚Šã‚‚ä½ã„ã€‚</p>
    <p>z-scoreã®çµ¶å¯¾å€¤ã¯æ¨™æº–åå·®ã¨ç­‰ã—ããªã‚‹ã€‚</p>
    <p>æ­£è¦åˆ†å¸ƒã®ã†ã¡ã€<br/>
        68%ã®ãƒ‡ãƒ¼ã‚¿ã¯z-scoreãŒ$-1$ã‹ã‚‰$1$ã®ç¯„å›²ã«åã¾ã‚Šã€<br/>
        95%ã®ãƒ‡ãƒ¼ã‚¿ã¯z-scoreãŒ$-2$ã‹ã‚‰$2$ã®ç¯„å›²ã«åã¾ã‚Šã€<br/>
        99.7%ã®ãƒ‡ãƒ¼ã‚¿ã¯z-scoreãŒ$-3$ã‹ã‚‰$3$ã®ç¯„å›²ã«åã¾ã‚‹ã€‚</p>
    <h3>Webãƒšãƒ¼ã‚¸ã®éŸ³å£°ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæ¥½ã ã£ãŸæ–¹æ³•</h3>
    <p>ç”ŸæˆAIã«Webã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ã‚‚ã‚‰ã†ã®ãŒä¸€ç•ªæ—©ã„ã€‚</p>
    <p>ä»Šå›ã¯<a href="https://www.aa.tufs.ac.jp/~mmine/kiki_gen/murasaki/">ã€æµ…äº•ã‚¿ã‚±æ˜”è©±å…¨é›† I, IIã€ ï¼ˆæ‘å´æ­å­ ç·¨è¨³ï¼‰</a>ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã€‚ã“ã®ã¨ãã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®Pythonã‚³ãƒ¼ãƒ‰ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚</p>
    
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            #!/usr/bin/env python3
            """
            æµ…äº•ã‚¿ã‚±æ˜”è©±é›†ã‹ã‚‰ã™ã¹ã¦ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
            https://www.aa.tufs.ac.jp/~mmine/kiki_gen/murasaki/asai01.html
            """
                    
            import requests
            from bs4 import BeautifulSoup
            import re
            from urllib.parse import urljoin
            import os
            import time
            from pathlib import Path
            import json
            from tqdm import tqdm
                    
            def download_asai_collection():
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                base_dir = Path('data/samples')
                asai_dir = base_dir / 'asai_take_stories'
                asai_dir.mkdir(exist_ok=True)
                    
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’è¨˜éŒ²ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                metadata_file = asai_dir / 'metadata.json'
                metadata = {
                    'collection': 'Asai Take Folktale Collection',
                    'source': 'https://www.aa.tufs.ac.jp/~mmine/kiki_gen/murasaki/asai01.html',
                    'stories': {}
                }
                
                # ç‰©èªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ™ãƒ¼ã‚¹URL
                base_url = 'https://www.aa.tufs.ac.jp/~mmine/kiki_gen/murasaki/'
                
                print('æµ…äº•ã‚¿ã‚±éŸ³å£°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...')
                print(f'ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {asai_dir}')
                
                # ã™ã¹ã¦ã®ç‰©èªãƒšãƒ¼ã‚¸ã®URLã‚’ç”Ÿæˆï¼ˆAt01ã‹ã‚‰At54ã¾ã§ï¼‰
                story_urls = []
                for i in range(1, 55):  # 1ã‹ã‚‰54ã¾ã§
                    story_url = f'{base_url}at{i:02d}aj.html'
                    story_urls.append((i, story_url))
                
                print(f'å‡¦ç†å¯¾è±¡ã®ç‰©èªãƒšãƒ¼ã‚¸æ•°: {len(story_urls)}')
                
                total_downloaded = 0
                total_audio_files = 0
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§ã™ã¹ã¦ã®ç‰©èªã‚’å‡¦ç†
                for story_num, story_url in tqdm(story_urls, desc="ç‰©èªã‚’å‡¦ç†ä¸­"):
                    story_id = f"At{story_num:02d}"
                    print(f'\\n{story_id}ã‚’å‡¦ç†ä¸­: {story_url}')
                    
                    try:
                        response = requests.get(story_url, timeout=30)
                        response.raise_for_status()
                        soup = BeautifulSoup(response.content, 'html.parser')
                        
                        # ã“ã®ãƒšãƒ¼ã‚¸å†…ã®éŸ³å£°ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
                        audio_links = []
                        for link in soup.find_all('a', href=True):
                            href = link['href']
                            if any(ext in href.lower() for ext in ['.wav', '.mp3', '.au', '.aiff']):
                                full_url = urljoin(story_url, href)
                                audio_links.append(full_url)
                        
                        print(f'  ç™ºè¦‹ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(audio_links)}')
                        total_audio_files += len(audio_links)
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§å„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        story_downloaded = 0
                        for i, audio_url in enumerate(tqdm(audio_links, desc=f"  {story_id} éŸ³å£°", leave=False)):
                            filename = f'{story_id}_{i+1:03d}.wav'
                            filepath = asai_dir / filename
                            
                            # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                            if filepath.exists():
                                print(f'    âš¡ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ï¼‰: {filename}')
                                story_downloaded += 1
                                continue
                            
                            try:
                                audio_response = requests.get(audio_url, timeout=30)
                                audio_response.raise_for_status()
                                
                                with open(filepath, 'wb') as f:
                                    f.write(audio_response.content)
                                
                                story_downloaded += 1
                                print(f'    âœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {filename} ({len(audio_response.content)} ãƒã‚¤ãƒˆ)')
                                
                            except Exception as e:
                                print(f'    âœ— ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— {audio_url}: {e}')
                            
                            time.sleep(0.3)  # ã‚µãƒ¼ãƒãƒ¼ã«é…æ…®ã—ãŸå¾…æ©Ÿæ™‚é–“
                        
                        total_downloaded += story_downloaded
                        
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
                        metadata['stories'][story_id] = {
                            'url': story_url,
                            'audio_files_found': len(audio_links),
                            'audio_files_downloaded': story_downloaded,
                            'title': f'ç‰©èª {story_num}'  # å®Ÿéš›ã®ã‚¿ã‚¤ãƒˆãƒ«ã§ã•ã‚‰ã«æ”¹å–„å¯èƒ½
                        }
                        
                        print(f'  âœ“ {story_id}: {story_downloaded}/{len(audio_links)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
                        
                    except Exception as e:
                        print(f'  âœ— {story_url}ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}')
                        metadata['stories'][story_id] = {
                            'url': story_url,
                            'error': str(e)
                        }
                    
                    # å®šæœŸçš„ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                    if story_num % 5 == 0:
                        with open(metadata_file, 'w', encoding='utf-8') as f:
                            json.dump(metadata, f, indent=2, ensure_ascii=False)
                    
                # æœ€çµ‚çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                metadata['total_stories'] = len(story_urls)
                metadata['total_audio_files_found'] = total_audio_files
                metadata['total_audio_files_downloaded'] = total_downloaded
                    
                with open(metadata_file, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)
                    
                print(f'\\nğŸ‰ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼')
                print(f'ğŸ“Š çµ±è¨ˆæƒ…å ±:')
                print(f'   å‡¦ç†ã—ãŸç‰©èªæ•°: {len(story_urls)}')
                print(f'   ç™ºè¦‹ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {total_audio_files}')
                print(f'   ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ•°: {total_downloaded}')
                print(f'   ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {asai_dir}')
                print(f'   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å…ˆ: {metadata_file}')
                    
                return asai_dir, total_downloaded, total_audio_files
                    
            if __name__ == '__main__':
                download_asai_collection()
        </code></pre>
    </div>
    </section>

    <?php renderAdBanner(); ?>

    <section>
      <h2>2025/09/11</h2>
    <h3>ã‚¢ã‚¤ãƒŒèªã®ã‚µã‚¤ãƒˆ</h3>
    <h4>éŸ³å£°ã¾ã¨ã‚ã‚µã‚¤ãƒˆ</h4>
    <a href="https://akitaben.com/category19/entry238.html">ç„¡æ–™ã§ä½¿ãˆã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã®ã‚¢ã‚¤ãƒŒèªè³‡æ–™ãƒ»ã‚¢ã‚¤ãƒŒèªæ•™æã®ã”ç´¹ä»‹(ã‚¢ã‚¤ãƒŒèªã‚’å‹‰å¼·ãƒ»å­¦ç¿’ã—ãŸã„äººã®ãŸã‚ã«)</a>
    <h4>ã‚¢ã‚¤ãƒŒèªè¾æ›¸</h4>
    <a href="https://www.ff-ainu.or.jp/teach/files/saru_tango.pdf">ã‚¢ã‚¤ãƒŒèªè¾æ›¸</a>

    <h3>Pythonã®å‹‰å¼·</h3>
    <h4>suffix.lower()ã®ä½¿ã„æ–¹</h4>
    <p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹"suffix.lower()"ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ ¼ç´ã—ã¦ã„ã‚‹"p"ã®æ‹¡å¼µå­ãŒ"AUDIO_EXTS"ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            def list_audio_files(folder: Path) -> List[Path]:
            # AUDIO_EXTSã«ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã€‚
            return [p for p in folder.rglob('*') if p.suffix.lower() in AUDIO_EXTS]
        </code></pre>
    </div>
    <h4>audio_urilsã®trim_silenceã«ã¤ã„ã¦</h4>
    <p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ã«"trim_silence"ã¯"top_db"ã§æŒ‡å®šã—ãŸãƒ‡ã‚·ãƒ™ãƒ«ä»¥ä¸‹ã®éŸ³å£°ã‚’ã‚«ãƒƒãƒˆã™ã‚‹é–¢æ•°ã§ã‚ã‚‹ã€‚ã¾ãŸã€0.01ç§’ã®é–“éš”ã§ã‚«ãƒƒãƒˆã‚’è¡Œã†ãŸã‚ã€0.01ç§’ä»¥ä¸Šã®ç„¡éŸ³éƒ¨åˆ†ã‚’ã‚«ãƒƒãƒˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            TRIM_DB = 30.0
            trimmed_audio = trim_silence(rec_audio, top_db=TRIM_DB)
        </code></pre>
    </div>

    <h4>notebookã®è¨˜è¿°ã®ã‚³ãƒ„</h4>
    <p>notebookã®ã‚»ãƒ«ã‚’ã¾ãŸãéš›ã«ã€ä¸€ã¤å‰ã®ã‚»ãƒ«ã®æœ€åˆã§å¤‰æ›´ã™ã‚‹äºˆå®šã®å¤‰æ•°ã‚’ã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã€æ¬¡ã®ã‚»ãƒ«ã®æœ€åˆã«æ¡ä»¶åˆ†å²ã«ã‚ˆã£ã¦ä¸€ã¤å‰ã®ã‚»ãƒ«ãŒå®Ÿè¡Œã•ã‚ŒãŸã‹ã‚’åˆ¤å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p>

      <div th:replace="~{fragments/ad :: adBanner}"></div>

    <h2>2025/09/12</h2>
    <h3>DTWã¨ã¯</h3>
    <p>DTW(Dynamic Time Warping)ã¯ã€2ã¤ã®æ™‚é–“è»¸ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é¡ä¼¼åº¦ã‚’å›³ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹ã€‚ã“ã®ã¨ãã€2ã¤ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯æ™‚é–“ãŒä¸€è‡´ã™ã‚‹å¿…è¦ãŒãªã„ã€‚</br>
    éŸ³å£°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ã‚°ãƒªãƒƒãƒ‰ã®è·é›¢ãŒæœ€çŸ­ã«ãªã‚‹ã‚ˆã†ã«é€Ÿã•ã‚’ã‚¹ãƒˆãƒ¬ãƒƒãƒã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹é€Ÿåº¦ã§è©±ã•ã‚Œã‚‹éŸ³å£°ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p>

    <h3>MFAã¨ã¯</h3>
    <p>éŸ³ç´ èªè­˜æŠ€è¡“ã®ä¸€ã¤ã§ã‚ã‚‹ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã®å¯¾å¿œé–¢ä¿‚ã‚’å­¦ç¿’ã—ã€æ–°ãŸãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦éŸ³ç´ ã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’è¡Œã†ã€‚</p>

    <h3>Pythonã®å‹‰å¼·</h3>
    <h4>tqdmã¨ã¯</h4>
    <p>tqdmã¨ã¯ã€notebookãªã©ã§ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã®éš›ã«è¦–è¦šçš„ã«ã‚ã‹ã‚Šã‚„ã™ã„ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã—ã¦ãã‚Œã‚‹ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã§ã‚ã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            TDTW scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2815/2815 [00:11<00:00, 243.06it/s]
        </code></pre>
    </div>
    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/09/25</h2>
    <h3>Pythonã®å‹‰å¼·</h3>
    <h4>librosa.feature.mfccã®å¼•æ•°ã«ã¤ã„ã¦</h4>
    <p>
        y: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®<br/>
        sr: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°<br/>
        n_mfcc: mfccã®æ¬¡å…ƒæ•°
    </p>

    <h3>GMMs(Gaussian Mixture Models)ã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹</h3>
    <p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ã«n_componentsã‚’16ã«è¨­å®šã™ã‚‹ã“ã¨ã§16å€‹ã®æ­£è¦åˆ†å¸ƒã®é‡ã­åˆã‚ã›ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            gmm = GaussianMixture(n_components=16, random_state=0)
        </code></pre>
    </div>
    <h4>GMMsé©ç”¨æ™‚ã®ã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦æ³•</h4>
    <p>ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ãŒå‡ºãŸéš›ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—ãŒæ­£ã—ãè¡Œã‚ã‚Œã¦ã„ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ã€‚å¤§æŠµã¯ã€MFCCã®ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ããŸã‚Šã€ä¼¼ã™ãã¦ã„ãŸã‚Šã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒåƒãã»ã©ã«ãƒ‡ãƒ¼ã‚¿ã«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒãªã„ã“ã¨ãŒå¤šã„ã€‚<br/>
    ãã®ãŸã‚ã€scikit-learnã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã‚’æ­£è¦åŒ–ã™ã‚‹ã“ã¨ã§è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚æ©Ÿæ¢°å­¦ç¿’ã«ãŠã„ã¦ã¯ã€æ­£è¦åŒ–ã‚’å¸¸ã«è¡Œã†ã“ã¨ãŒæ…£ä¾‹ã¨ãªã£ã¦ã„ã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            ---------------------------------------------------------------------------
            LinAlgError                               Traceback (most recent call last)
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/mixture/_gaussian_mixture.py:334, in _compute_precision_cholesky(covariances, covariance_type)
                333 try:
            --> 334     cov_chol = linalg.cholesky(covariance, lower=True)
                335 except linalg.LinAlgError:
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/scipy/_lib/_util.py:1233, in _apply_over_batch.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
               1232 if not any(batch_shapes):
            -> 1233     return f(*arrays, *other_args, **kwargs)
               1235 # Determine broadcasted batch shape
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/scipy/linalg/_decomp_cholesky.py:106, in cholesky(a, lower, overwrite_a, check_finite)
                 52 """
                 53 Compute the Cholesky decomposition of a matrix.
                 54 
               (...)    104 
                105 """
            --> 106 c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,
                107                      check_finite=check_finite)
                108 return c
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/scipy/linalg/_decomp_cholesky.py:39, in _cholesky(a, lower, overwrite_a, clean, check_finite)
                 38 if info &gt; 0:
            --> 39     raise LinAlgError(
                 40         f"{info}-th leading minor of the array is not positive definite"
                 41     )
                 42 if info &lt; 0:
            
            LinAlgError: 17-th leading minor of the array is not positive definite
            
            During handling of the above exception, another exception occurred:
            
            ValueError                                Traceback (most recent call last)
            Cell In[8], line 6
                  4 for speaker, features in speaker_features.items():
                  5     gmm = GaussianMixture(n_components=16, random_state=0)
            ----&gt; 6     gmm.fit(features)
                  7     gmm_models[speaker] = gmm
                  8     print(f"Model for {speaker} trained successfully.")
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/mixture/_base.py:182, in BaseMixture.fit(self, X, y)
                156 """Estimate model parameters with the EM algorithm.
                157 
                158 The method fits the model ``n_init`` times and sets the parameters with
               (...)    179     The fitted mixture.
                180 """
                181 # parameters are validated in fit_predict
            --&gt; 182 self.fit_predict(X, y)
                183 return self
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/base.py:1365, in _fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(estimator, *args, **kwargs)
               1358     estimator._validate_params()
               1360 with config_context(
               1361     skip_parameter_validation=(
               1362         prefer_skip_nested_validation or global_skip_validation
               1363     )
               1364 ):
            -&gt; 1365     return fit_method(estimator, *args, **kwargs)
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/mixture/_base.py:251, in BaseMixture.fit_predict(self, X, y)
                248 prev_lower_bound = lower_bound
                250 log_prob_norm, log_resp = self._e_step(X)
            --&gt; 251 self._m_step(X, log_resp)
                252 lower_bound = self._compute_lower_bound(log_resp, log_prob_norm)
                253 current_lower_bounds.append(lower_bound)
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/mixture/_gaussian_mixture.py:834, in GaussianMixture._m_step(self, X, log_resp)
                830 self.weights_, self.means_, self.covariances_ = _estimate_gaussian_parameters(
                831     X, np.exp(log_resp), self.reg_covar, self.covariance_type
                832 )
                833 self.weights_ /= self.weights_.sum()
            --&gt; 834 self.precisions_cholesky_ = _compute_precision_cholesky(
                835     self.covariances_, self.covariance_type
                836 )
            
            File ~/OneDrive/5years/graduation_research/ainu/venv/lib/python3.12/site-packages/sklearn/mixture/_gaussian_mixture.py:336, in _compute_precision_cholesky(covariances, covariance_type)
                334             cov_chol = linalg.cholesky(covariance, lower=True)
                335         except linalg.LinAlgError:
            --&gt; 336             raise ValueError(estimate_precision_error_message)
                337         precisions_chol[k] = linalg.solve_triangular(
                338             cov_chol, np.eye(n_features, dtype=dtype), lower=True
                339         ).T
                340 elif covariance_type == "tied":
            
            ValueError: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, increase reg_covar, or scale the input data. The numerical accuracy can also be improved by passing float64 data instead of float32.
            
             (See &lt;attachments&gt; above for file contents. You may not need to search or read the file again.)
        </code></pre>
    </div>

    <p>ä»¥ä¸Šã®ã‚¨ãƒ©ãƒ¼ã‚’ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ã§all_featuresã‚’æ­£è¦åŒ–ã—ãŸã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                scaled_features = scaler.fit_transform(all_features)
        </code></pre>
    </div>

    <p>ã¾ãŸã€ä»¥ä¸‹ã®ã‚ˆã†ã«reg_covarã‚’GaussianMixtureã«è¨­å®šã™ã‚‹ã“ã¨ã§ã€å…±åˆ†æ•£ã‚’æ­£ã®æ­£è¦åŒ–ã™ã‚‹ã®ã§åæŸæ™‚ã«ä¸å®‰å®šã«ãªã‚‹ã“ã¨ã‚’é˜²ãã“ã¨ãŒã§ãã‚‹ã€‚</p>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
                gmm = GaussianMixture(n_components=16, random_state=0, reg_covar=1e-6)
        </code></pre>
    </div>

    <h3>çµæœãŒä¸€æ–¹ã«åã£ãŸéš›ã®å¯¾å‡¦æ³•</h3>
    <p>GMMsã«ã‚ˆã‚‹åˆ†é¡ã®çµæœãŒã€ç‰¹å®šã®å¯¾è±¡ã®ã¿ã«åã£ãŸå ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ãŒåŸå› ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚</p>
    <h4>ã‚³ãƒ¼ãƒ‰</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            def extract_features(file_path):
                try:
                    audio, sample_rate = librosa.load(file_path, sr=16000)
                    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=20)

                    # each row is a time frame and each column is an MFCC coefficient
                    return mfccs.T

                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
                    return None

            all_features = {}
            speaker_features = {}
            #store the scaler for each speaker
            scalers = {}
            for speaker, paths in speaker_paths.items():
                combined_features = []
                print(f"Extracting features for {speaker}...")
                for path in paths:
                    features = extract_features(path)
                    if features is not None:
                        combined_features.append(features)

                all_features[speaker] = np.vstack(combined_features)

                scaler = StandardScaler()
                scaled_features = scaler.fit_transform(all_features[speaker])

                speaker_features[speaker] = scaled_features
                scalers[speaker] = scaler

                print(f"Finished extracting features for {speaker}. Shape: {speaker_features[speaker].shape}")
        </code></pre>
    </div>

    <h4>çµæœ</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            Extracting features for Speaker1...
            Finished extracting features for Speaker1. Shape: (711208, 20)
            Extracting features for Speaker2...
            Finished extracting features for Speaker2. Shape: (257415, 20)
        </code></pre>
    </div>

    <p>
        ä»¥ä¸Šã®æ§˜ã«Speaker1ã®ãƒ‡ãƒ¼ã‚¿ã®é‡ãŒSpeaker2ã«æ¯”ã¹ã¦3å€ä»¥ä¸Šã§ã‚ã‚‹ã€‚ãã®ãŸã‚æ¯”è¼ƒçš„ã«ã€Speaker1ã®ãƒ‡ãƒ¼ã‚¿ã¯å…¨ä½“ã¨ã—ã¦åŒ…æ‹¬çš„ã«éŸ³éŸ¿ã‚’åˆ†æã—ã€Speaker2ã®ãƒ‡ãƒ¼ã‚¿ã¯ç‰¹å¾´çš„ãªéƒ¨åˆ†ã‚’ä¸­å¿ƒçš„ã«åˆ†æã—ã¦ã—ã¾ã†ã€‚<br/>
        çµæœçš„ã«ã€ãƒ†ã‚¹ãƒˆã®éš›ã«Speaker2ã®éŸ³å£°ã«å¯¾ã—ã¦ã¯ååˆ†ã«æ³¢å½¢ãŒè¿‘ã„ã“ã¨ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ãŸã‚åˆ†é¡ã®çµæœãŒSpeaker1ã«åã£ã¦ã—ã¾ã†ã€‚<br/>
        è§£æ±ºæ³•ã¨ã—ã¦ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡ç­‰ãªé‡ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
    </p>

    <p>
        ãã‚Œã§ã‚‚ãªãŠè§£æ±ºã—ãªã‹ã£ãŸã€‚åŸå› ã¯ãƒ†ã‚¹ãƒˆæ™‚ã«ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ã™ã‚‹ã®ã‚’å¿˜ã‚Œã¦ã„ãŸãŸã‚ã ã£ãŸã€‚<br/>
        ä»¥ä¸‹ã®ã‚ˆã†ã«scalersã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ä¿®æ­£ã—ãŸã€‚
    </p>

    <h4>ä¿®æ­£å‰</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            def predict_speaker(file_path, models):
                unknown_features = extract_features(file_path)
                if unknown_features is None:
                    return "Could not process audio."

                scores = {}
                for speaker, gmm in models.items():
                    scores[speaker] = gmm.score(unknown_features)

                predicted_speaker = max(scores, key=scores.get)

                return predicted_speaker, scores[predicted_speaker]
        </code></pre>
    </div>

    <h4>ä¿®æ­£å¾Œ</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            def predict_speaker(file_path, models, scalers):
                unknown_features = extract_features(file_path)
                if unknown_features is None:
                    return "Could not process audio.", 0

                scores = {}
                for speaker, gmm in models.items():
                    scaler = scalers[speaker]
                    scaled_unknown_features = scaler.transform(unknown_features)

                    scores[speaker] = gmm.score(scaled_unknown_features)

                predicted_speaker = max(scores, key=scores.get)

                return predicted_speaker, scores[predicted_speaker]
        </code></pre>
    </div>

    <h3>çµæœã‚’CSVã§ä¿å­˜ã™ã‚‹ã¨ãã®æ—¥æ™‚ã®æŒ‡å®š</h3>
    <p>
        ã€Œ<a href="https://note.nkmk.me/python-datetime-now-today/">Pythonã§ç¾åœ¨æ™‚åˆ»ãƒ»æ—¥ä»˜ãƒ»æ—¥æ™‚ã‚’å–å¾—</a>ã€ã“ã®ã‚µã‚¤ãƒˆã‚’å‚è€ƒã«ã—ãŸã€‚
    </p>
    
    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/09/26</h2>
    <h3>Deep Learningã®ãƒ‡ãƒ¼ã‚¿çµ„è¾¼æ™‚ã®RAMã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦æ³•</h3>
    <p>
        ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚ˆã‚Šã€å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ã†éš›ã«è†¨å¤§ãªRAMã‚’æ¶ˆè²»ã—ãŸã“ã¨ãŒåŸå› ã§ã‚ã‚‹ã¨æ¨æ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
    </p>

    <h4>ãƒ—ãƒ­ã‚°ãƒ©ãƒ </h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            def get_embedding(file_path, model):
                try:
                    signal, fs = librosa.load(file_path, sr=16000)
                    audio_tensor = torch.from_numpy(signal)

                    embedding = model.encode_batch(audio_tensor)
                    embedding = embedding.squeeze().cpu().numpy()

                    return embedding
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
                    return None

            speaker_embedding_db = {}

            print("Creating speaker embedding database from training data...")
            for speaker, paths in speaker_paths_train.items():
                embeddings = []
                for path in paths:
                    embedding = get_embedding(path, language_id)
                    if embedding is not None:
                        embeddings.append(embedding)

                if embeddings:
                    speaker_embedding_db[speaker] = np.mean(embeddings, axis=0)
                    print(f"Created avarage embedding for {speaker}.")

            print("/n--- Speaker Embedding Database Complete ---")
        </code></pre>
    </div>

    <h4>app.log</h4>
    <div class="md-table-wrap">
        <table class="md-table">
            <thead>
                <tr>
                    <th>Timestamp</th>
                    <th>Level</th>
                    <th>Message</th>
                </tr>
            </thead>
            <tbody>
                <tr><td>Sep 26, 2025, 11:02:06 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 11:02:06 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 11:02:06 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 11:02:06 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 11:02:05 AM</td><td>WARNING</td><td>kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted</td></tr>
                <tr><td>Sep 26, 2025, 11:02:05 AM</td><td>INFO</td><td>AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports</td></tr>
                <tr><td>Sep 26, 2025, 10:58:54 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 10:58:54 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 10:58:54 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 10:58:54 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 10:58:53 AM</td><td>INFO</td><td>Kernel restarted: 527821a1-c507-43c3-805c-40394db7bda6</td></tr>
                <tr><td>Sep 26, 2025, 10:58:02 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 10:58:02 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 10:58:02 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 10:58:02 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 10:58:01 AM</td><td>WARNING</td><td>kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted</td></tr>
                <tr><td>Sep 26, 2025, 10:58:01 AM</td><td>INFO</td><td>AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports</td></tr>
                <tr><td>Sep 26, 2025, 10:53:05 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 10:53:05 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 10:53:05 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 10:53:05 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 10:53:04 AM</td><td>WARNING</td><td>kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted</td></tr>
                <tr><td>Sep 26, 2025, 10:53:04 AM</td><td>INFO</td><td>AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports</td></tr>
                <tr><td>Sep 26, 2025, 10:48:47 AM</td><td>INFO</td><td>Connecting to kernel 527821a1-c507-43c3-805c-40394db7bda6.</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>INFO</td><td>Kernel started: 527821a1-c507-43c3-805c-40394db7bda6</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>validate_schema(_schema)</td></tr>
                <tr><td>Sep 26, 2025, 10:48:46 AM</td><td>WARNING</td><td>/usr/local/lib/python3.12/dist-packages/jupyter_events/schema.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string. It has been type coerced, but in a future version of this library, it will fail to validate. Please update schema: https://events.jupyter.org/jupyter_server/kernel_actions/v1</td></tr>
                <tr><td>Sep 26, 2025, 10:48:45 AM</td><td>WARNING</td><td>0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.</td></tr>
                <tr><td>Sep 26, 2025, 10:48:45 AM</td><td>WARNING</td><td>0.00s - to python to disable frozen modules.</td></tr>
                <tr><td>Sep 26, 2025, 10:48:45 AM</td><td>WARNING</td><td>0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off</td></tr>
                <tr><td>Sep 26, 2025, 10:48:45 AM</td><td>WARNING</td><td>0.00s - Debugger warning: It seems that frozen modules are being used, which may</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>http://127.0.0.1:9000/</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>http://172.28.0.12:9000/</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>Jupyter Server 2.14.0 is running at:</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>Serving notebooks from local directory: /</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>panel.io.jupyter_server_extension</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>nbclassic</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>jupyterlab_jupytext</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>[Jupytext Server Extension] Deriving an AsyncTextFileContentsManager from AsyncLargeFileManager</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>jupyter_server_terminals</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>ipyparallel</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>Loading IPython parallel extension</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>google.colab._serverextension</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>google.colab server extension initialized.</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>google.colab</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>notebook_shim</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>Customizing authentication via ServerApp.login_handler_class=&lt;class 'google.colab._login_handler.ColabLoginHandler'&gt; is deprecated in Jupyter Server 2.0. Use ServerApp.identity_provider_class. Falling back on legacy authentication.</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>panel.io.jupyter_server_extension</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>INFO</td><td>notebook_shim</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/root/.jupyter/jupyter_notebook_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/root/.local/etc/jupyter/jupyter_notebook_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/usr/etc/jupyter/jupyter_notebook_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_notebook_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_notebook_config.d/jupytext.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_notebook_config.d/ipyparallel.json</td></tr>
                <tr><td>Sep 26, 2025, 10:45:02 AM</td><td>WARNING</td><td>/etc/jupyter/jupyter_notebook_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>validate_schema(_schema)</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/lib/python3.12/dist-packages/jupyter_events/schema.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string. It has been type coerced, but in a future version of this library, it will fail to validate. Please update schema: https://events.jupyter.org/jupyter_server/gateway_client/v1</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>validate_schema(_schema)</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/lib/python3.12/dist-packages/jupyter_events/schema.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string. It has been type coerced, but in a future version of this library, it will fail to validate. Please update schema: https://events.jupyter.org/jupyter_server/contents_service/v1</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/root/.jupyter/jupyter_server_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/root/.local/etc/jupyter/jupyter_server_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/etc/jupyter/jupyter_server_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/nbclassic.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/google.colab.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/panel-client-jupyter.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/notebook_shim.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/nbclassic.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/jupytext.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/jupyter_server_terminals.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/ipyparallel.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/usr/local/etc/jupyter/jupyter_server_config.d/google.colab._serverextension.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>/etc/jupyter/jupyter_server_config.json</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>ServerApp.iopub_data_rate_limit config is deprecated in 2.0. Use ZMQChannelsWebsocketConnection.iopub_data_rate_limit.</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>[W 2025-09-26 01:44:59.341 ServerApp] ServerApp.token config is deprecated in 2.0. Use IdentityProvider.token.</td></tr>
                <tr><td>Sep 26, 2025, 10:44:59 AM</td><td>WARNING</td><td>warn(</td></tr>
            </tbody>
        </table>
    </div>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            |Timestamp|Level|Message|
            |---|---|---|
            |Sep 26, 2025, 11:02:06â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 11:02:06â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 11:02:06â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 11:02:06â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 11:02:05â€¯AM|WARNING|kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted|
            |Sep 26, 2025, 11:02:05â€¯AM|INFO|AsyncIOLoopKernelRestarter: restarting kernel \(1/5\), keep random ports|
            |Sep 26, 2025, 10:58:54â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 10:58:54â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 10:58:54â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 10:58:54â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 10:58:53â€¯AM|INFO|Kernel restarted: 527821a1-c507-43c3-805c-40394db7bda6|
            |Sep 26, 2025, 10:58:02â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 10:58:02â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 10:58:02â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 10:58:02â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 10:58:01â€¯AM|WARNING|kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted|
            |Sep 26, 2025, 10:58:01â€¯AM|INFO|AsyncIOLoopKernelRestarter: restarting kernel \(1/5\), keep random ports|
            |Sep 26, 2025, 10:53:05â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 10:53:05â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 10:53:05â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 10:53:05â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 10:53:04â€¯AM|WARNING|kernel 527821a1-c507-43c3-805c-40394db7bda6 restarted|
            |Sep 26, 2025, 10:53:04â€¯AM|INFO|AsyncIOLoopKernelRestarter: restarting kernel \(1/5\), keep random ports|
            |Sep 26, 2025, 10:48:47â€¯AM|INFO|Connecting to kernel 527821a1-c507-43c3-805c-40394db7bda6\.|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 10:48:46â€¯AM|INFO|Kernel started: 527821a1-c507-43c3-805c-40394db7bda6|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|  validate\_schema\(\_schema\)|
            |Sep 26, 2025, 10:48:46â€¯AM|WARNING|/usr/local/lib/python3\.12/dist-packages/jupyter\_events/schema\.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string\. It has been type coerced, but in a future version of this library, it will fail to validate\. Please update schema: https://events\.jupyter\.org/jupyter\_server/kernel\_actions/v1|
            |Sep 26, 2025, 10:48:45â€¯AM|WARNING|0\.00s - Note: Debugging will proceed\. Set PYDEVD\_DISABLE\_FILE\_VALIDATION=1 to disable this validation\.|
            |Sep 26, 2025, 10:48:45â€¯AM|WARNING|0\.00s - to python to disable frozen modules\.|
            |Sep 26, 2025, 10:48:45â€¯AM|WARNING|0\.00s - make the debugger miss breakpoints\. Please pass -Xfrozen\_modules=off|
            |Sep 26, 2025, 10:48:45â€¯AM|WARNING|0\.00s - Debugger warning: It seems that frozen modules are being used, which may|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Use Control-C to stop this server and shut down all kernels \(twice to skip confirmation\)\.|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|    http://127\.0\.0\.1:9000/|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|http://172\.28\.0\.12:9000/|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Jupyter Server 2\.14\.0 is running at:|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Serving notebooks from local directory: /|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|panel\.io\.jupyter\_server\_extension |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|nbclassic |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|jupyterlab\_jupytext |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|\[Jupytext Server Extension\] Deriving an AsyncTextFileContentsManager from AsyncLargeFileManager|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|jupyter\_server\_terminals |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|ipyparallel |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Loading IPython parallel extension|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|google\.colab\._serverextension |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|google\.colab server extension initialized\.|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|google\.colab |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|notebook\_shim |
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|Customizing authentication via ServerApp\.login\_handler\_class=\<class 'google\.colab\._login\_handler.ColabLoginHandler'\> is deprecated in Jupyter Server 2\.0\. Use ServerApp\.identity\_provider\_class\. Falling back on legacy authentication.|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|panel\.io\.jupyter\_server\_extension |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|notebook\_shim |
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/root/\.jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/root/\.local/etc/jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/usr/etc/jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_notebook\_config\.d/panel-client-jupyter\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_notebook\_config\.d/jupytext\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_notebook\_config\.d/ipyparallel\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/etc/jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|WARNING|    \t/root/\.jupyter/jupyter\_notebook\_config\.json|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Writing Jupyter server cookie secret to /root/\.local/share/jupyter/runtime/jupyter\_cookie\_secret|
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|nbclassic |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|jupyterlab\_jupytext |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|jupyter\_server\_terminals |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|ipyparallel |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|google\.colab\._serverextension |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|google\.colab |
            |Sep 26, 2025, 10:45:02â€¯AM|INFO|Extension package panel\.io\.jupyter\_server\_extension took 1\.8744s to import|
            |Sep 26, 2025, 10:45:00â€¯AM|WARNING|A `\_jupyter\_server\_extension\_points` function was not found in nbclassic\. Instead, a `\_jupyter\_server\_extension\_paths` function was found and will be used for now\. This function name will be deprecated in future releases of Jupyter Server.|
            |Sep 26, 2025, 10:45:00â€¯AM|INFO|Extension package jupyterlab\_jupytext took 0\.1630s to import|
            |Sep 26, 2025, 10:45:00â€¯AM|WARNING|A `\_jupyter\_server\_extension\_points` function was not found in ipyparallel\. Instead, a `\_jupyter\_server\_extension\_paths` function was found and will be used for now\. This function name will be deprecated in future releases of Jupyter Server.|
            |Sep 26, 2025, 10:45:00â€¯AM|INFO|Extension package ipyparallel took 0\.2001s to import|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|  validate\_schema\(\_schema\)|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|/usr/local/lib/python3\.12/dist-packages/jupyter\_events/schema\.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string\. It has been type coerced, but in a future version of this library, it will fail to validate\. Please update schema: https://events\.jupyter\.org/jupyter\_server/gateway\_client/v1|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|  validate\_schema\(\_schema\)|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|/usr/local/lib/python3\.12/dist-packages/jupyter\_events/schema\.py:68: JupyterEventsVersionWarning: The `version` property of an event schema must be a string\. It has been type coerced, but in a future version of this library, it will fail to validate\. Please update schema: https://events\.jupyter\.org/jupyter\_server/contents\_service/v1|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/root/\.jupyter/jupyter\_server\_config\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/root/\.local/etc/jupyter/jupyter\_server\_config\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/etc/jupyter/jupyter\_server\_config\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/nbclassic\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/google\.colab\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/panel-client-jupyter\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/notebook\_shim\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/nbclassic\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/jupytext\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/jupyter\_server\_terminals\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/ipyparallel\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/usr/local/etc/jupyter/jupyter\_server\_config\.d/google\.colab\._serverextension\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|    \t/etc/jupyter/jupyter\_server\_config\.json|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|ServerApp\.iopub\_data\_rate\_limit config is deprecated in 2\.0\. Use ZMQChannelsWebsocketConnection\.iopub\_data\_rate\_limit.|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|\[W 2025-09-26 01:44:59\.341 ServerApp\] ServerApp\.token config is deprecated in 2\.0\. Use IdentityProvider\.token.|
            |Sep 26, 2025, 10:44:59â€¯AM|WARNING|  warn\(|
        </code></pre>
    </div>
    <p>
        ã“ã®çŠ¶æ…‹ã§ã¯ä¸€å›ã«èª­ã¿è¾¼ã‚€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ•°åˆ†ã§ã‚ã‚Šé•·ã„ãŸã‚ãƒ¡ãƒ¢ãƒªã‚’ä½™åˆ†ã«ä½¿ã£ã¦ã—ã¾ã†ã€‚
        ãã®ãŸã‚ã€ä»¥ä¸‹ã®ã‚ˆã†ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç´°ã‹ãåˆ†ã‘ã¦çµ„ã¿è¾¼ã¿ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã¨ã—ãŸã€‚
        ãã†ã™ã‚‹ã“ã¨ã§ãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚’æŠ‘ãˆã‚‹ã“ã¨ã«æˆåŠŸã—ãŸã€‚
    </p>

    <h4>ä¿®æ­£å¾Œã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ </h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
        def get_embedding_chunked(file_path, model, chunk_length_sec=10):
            try:
                signal, fs = librosa.load(file_path, sr=16000)

                chunk_size = chunk_length_sec * fs
                chunk_embeddings = []

                for i in range(0, len(signal), chunk_size):
                    chunk = signal[i:i+chunk_size]

                    if len(chunk) < fs * 1:
                        #Skip chunks that are too short
                        continue

                    audio_tensor = torch.from_numpy(chunk)

                    embedding = model.encode_batch(audio_tensor)
                    embedding = embedding.squeeze().cpu().numpy()

                    chunk_embeddings.append(embedding)

                if not chunk_embeddings:
                    print(f"Warning: No valid chunks found for {os.path.basename(file_path)}")
                    return None

                final_embedding = np.mean(chunk_embeddings, axis=0)
                return final_embedding

            except Exception as e:
                print(f"Error processing {file_path}: {e}")
                return None

        speaker_embedding_db = {}

        print("Creating speaker embedding database from training data(using chunking)...")
        for speaker, paths in speaker_paths_train.items():
            embeddings = []
            for path in paths[:3]:
                embedding = get_embedding_chunked(path, language_id)
                if embedding is not None:
                    embeddings.append(embedding)
                    print(f"Processed {os.path.basename(path)}")

            if embeddings:
                speaker_embedding_db[speaker] = np.mean(embeddings, axis=0)
                print(f"Created average embedding for {speaker}.")

        print("/n--- Speaker Embedding Database Complete ---")
        </code></pre>
    </div>

    <h3>GPUãŒå…¨ãä½¿ã‚ã‚Œã¦ã„ãªã‹ã£ãŸã€‚</h3>
    <p>
        äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹éš›ã«ã€run_optsã§GPUã‚’æŒ‡å®šã—ã¦ã„ãªã‹ã£ãŸãŸã‚ã€CPUã§å‡¦ç†ãŒè¡Œã‚ã‚Œã¦ã„ãŸã€‚
        ãã®ãŸã‚ã€ä»¥ä¸‹ã®ã‚ˆã†ã«GPUã®è¨­å®šã‚’ã—ç›´ã—ã¦GPUã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚
    </p>

    <h4>ä¿®æ­£å‰ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ </h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            language_id = EncoderClassifier.from_hparams(
                source="speechbrain/spkrec-ecapa-voxceleb",
                savedir = root_path + "/models/pretrained_models/ecapa-tdnn"
                )

            print("Pre-trained model loaded successfully.")

            ...

            audio_tensor = torch.from_numpy(chunk)

            embedding = model.encode_batch(audio_tensor)
        </code></pre>
    </div>

    <h4>ä¿®æ­£å¾Œã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ </h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            device = "cuda" if torch.cuda.is_available() else "cpu"

            language_id = EncoderClassifier.from_hparams(
                source="speechbrain/spkrec-ecapa-voxceleb",
                savedir = root_path + "/models/pretrained_models/ecapa-tdnn",
                run_opts={"device": device}
                )

            print(f"Device is {device}")
            print("Pre-trained model loaded successfully.")

            ...

            audio_tensor = torch.from_numpy(chunk)
            audio_tensor = audio_tensor.to(device)
            embedding = model.encode_batch(audio_tensor)
        </code></pre>

    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/09/28</h2>
    <h3>t-SNEã¨ã¯</h3>
    <p>
        t-SNEã¯é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šçš„ã«è¡¨ã™ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚ã‚‹ã€‚
        ä»Šå›ã¯192æ¬¡å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã£ã¦ã„ãŸãŒã€2æ¬¡å…ƒã¨ã—ã¦è¦–è¦šåŒ–ã—ãŸã€‚
    </p>

    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/09/29</h2>
    <h3>t-SNEã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"n_iter"ãŒä½¿ãˆãªã„</h3>
    <p>
        t-SNEã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"n_iter"ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³1.5ä»¥é™ã§"max_iter"ã«åç§°ãŒå¤‰æ›´ã•ã‚ŒãŸã€‚
    </p>
    <h3>voiceprint extractorã¨ã¯</h3>
    <p>
        è©±è€…ç‰¹å®šã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯äº‹å‰å­¦ç¿’ã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚
        ãã®éš›ã«ä½¿ç”¨ã•ã‚Œã‚‹å¤§è¦æ¨¡ãªæ±ç”¨çš„ãªAIãƒ¢ãƒ‡ãƒ«ã®ä¸€ã¤ã«"voiceprint extractor"ãŒã‚ã‚‹ã€‚</br>
        ä»Šå›ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«"speechbrain/spkrec-ecapa-voxceleb"ã¯ã€äººé–“ãŒç™ºã›ã‚‰ã‚Œã‚‹éŸ³å£°ã‹ã‚‰ãƒ¯ãƒ¼ãƒ‰ã‚„è¨€èªã‚„ãƒã‚¤ã‚ºç­‰ã‚’ç„¡è¦–ã—ã¦å€‹äººã®ç‰¹å¾´é‡ã®ã¿ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚
    </p>
    <h3>ä»Šå›ä½œæˆã—ãŸè©±è€…ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚½ãƒƒãƒ‰</h3>
    <p>
        ä»Šå›ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€2ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã€‚
    </p>
    <p>
        ã¾ãš1ã¤ç›®ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€å¤§è¦æ¨¡ãªvoiceprint extractorã‚’ä½¿ç”¨ã—ã¦ã€éŸ³å£°ã‹ã‚‰è©±è€…å›ºæœ‰ã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        ä»Šå›ä½¿ç”¨ã—ãŸ"speechbrain/spkrec-ecapa-voxceleb"ã¯ã€éŸ³å£°ã‹ã‚‰192æ¬¡å…ƒã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã€‚ã“ã“ã§çµ„ã¿è¾¼ã‚€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ2ç§’ã ã‚ã†ãŒ30ç§’ã ã‚ã†ãŒ192å€‹ã®ç‰¹å¾´é‡ã«è¦ç´„ã•ã‚Œã‚‹ã€‚ãã†ã™ã‚‹ã“ã¨ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åŒå£«ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã«å„ªã‚Œã¦ã„ã‚‹ã€‚
    </p>
    <p>
        2ã¤ç›®ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€æŠ½å‡ºã—ãŸç‰¹å¾´é‡ã‚’ã‚‚ã¨ã«ã€è©±è€…ã®è­˜åˆ¥ã‚’è¡Œã†ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚ä»Šå›ã§ã¯ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ä½¿ç”¨ã—ãŸã€‚</br>
        æœ€åˆã«è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚ºã§Voiceprint Databaseã‚’ä½œæˆã™ã‚‹ã€‚ç”¨æ„ã—ãŸè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’voiceprint extractorã«çµ„ã¿è¾¼ã‚€ã€‚ã¾ãŸã€å„è©±è€…ã”ã¨ã«ç”¨æ„ã—ãŸè¤‡æ•°ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®voiceprintã‚’è©±è€…ã”ã¨ã«å¹³å‡ã‚’æ’®ã£ã¦è©±è€…ç‰¹æœ‰ã®voiceprintã‚’ä½œæˆã™ã‚‹ã€‚ãã®å¾Œã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦1ã€œ0ã®ç¯„å›²ã§é¡ä¼¼åº¦ã‚’æ±‚ã‚ã‚‹ã€‚
    </p>
    <h3>x-vectorã¨ã¯</h3>
    <p>
        x-vectorã¨ã¯ã€voiceprintã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«æŠ½å‡ºã™ã‚‹ç‰¹å¾´é‡ã®è¨ˆç®—æ–¹æ³•ã§ã‚ã‚‹ã€‚
    </p>
    <h4>x-vectorã®è¨ˆç®—æ–¹æ³•</h4>
    <p>
        x-vectorã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—ãŒè¡Œã‚ã‚Œã‚‹ã€‚
        ã¾ãšã€æœ€åˆã«éŸ³å£°ã‚’ç´°ã‹ãåˆ†ã‘ã¦é‡ãªã‚Šåˆã†éƒ¨åˆ†ã‚’è§£æã™ã‚‹ã€‚ã“ã®ã¨ãTime Delay Neural Network(TDNN)ã‚’ä½¿ç”¨ã™ã‚‹ã€‚TDNNã¯éŸ³å£°ã®æ™‚é–“é ˜åŸŸã§ã®ç‰¹å¾´é‡ã®æŠ½å‡ºã«å„ªã‚Œã¦ã„ã‚‹ã€‚TDNNã«ã‚ˆã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç´°ã‹ã„æ™‚é–“ã”ã¨ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æŠ½å‡ºã«é•·ã‘ã¦ã„ã‚‹ã€‚
        ãã®å¾Œã€çµ±è¨ˆçš„ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã€‚ã“ã®ã¨ãå…¨ä½“ã®ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®ç‰¹å¾´é‡ã®å¹³å‡ã‚„æ­£è¦åˆ†å¸ƒã‚’è¨ˆç®—ã—ã¦ãã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã€‚ãã†ã™ã‚‹ã“ã¨ã§ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã¨ã—ã¦ã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
        æœ€çµ‚çš„ã«ã¯ã ã„ãŸã„128~512æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã®ç‰¹å¾´é‡ã«æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
    </p>
    <h3>éŸ³å£°ãŒæŒã¤ãƒ‡ãƒ¼ã‚¿ã®æ•°</h3>
    <p>
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€æ™‚é–“ã®æƒ…å ±ã¨å¤§ãã•ã®æƒ…å ±ã—ã‹ãªã„ã€‚
        ãŸã ã—ã€æ™‚é–“ã‚’ç¬é–“çš„ã«åˆ‡ã‚Šå–ã‚‹ã¨ãã®æ™‚ã®å‘¨æ³¢æ•°ã”ã¨ã®ç‰¹æ€§ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
        ã“ã®ã¨ãFFTã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã‚ã‚‹ãŒã€ä¾‹ãˆã°100ãƒ•ãƒ¬ãƒ¼ãƒ ã®512æ¬¡å…ƒã§ã®è§£æã§ã¯257æ¬¡å…ƒã®å‘¨æ³¢æ•°ã”ã¨ã®æŒ¯å¹…ã‚’å¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã€‚ã“ã®ã¨ãã®ãƒ‡ãƒ¼ã‚¿ã®æ•°ã¯100x257=25700å€‹ã§ã‚ã‚Šã€ã“ã‚Œã‚’ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’è¨€ã†ã€‚
        ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã„ã¦ã¯ã€ã“ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ç‹¬è‡ªã®è¨ˆç®—ã§é‡ã¿ä»˜ã‘ã™ã‚‹ã‚ˆã†ãªå­¦ç¿’ã‚’è¡Œã†ã€‚
    </p>

    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/10/02</h2>
    <h3>TTSã®ä½¿ç”¨æ™‚ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼</h3>
    <p>
        ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸéš›ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒãƒ³ãƒ‰ã§Linuxã«mecabã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
    </p>

    <h4>TTSä½¿ç”¨æ™‚ã®ã‚¨ãƒ©ãƒ¼</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            ---------------------------------------------------------------------------
            RuntimeError                              Traceback (most recent call last)
            Cell In[9], line 2
                  1 print("Cloning the voice and generating speech...")
            ----> 2 tts.tts_to_file(
                  3     text=text_to_synthesize,
                  4     speaker_wav=speaker_wav_path,
                  5     language="ja",  # Specify Japanese
                  6     file_path=output_wav_path
                  7 )
                  9 print(f"Speech generated successfully and saved to {output_wav_path}")

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/api.py:334, in TTS.tts_to_file(self, text, speaker, language, speaker_wav, emotion, speed, pipe_out, file_path, split_sentences, **kwargs)
                303 """Convert text to speech.
                304 
                305 Args:
               (...)    330         Additional arguments for the model.
                331 """
                332 self._check_arguments(speaker=speaker, language=language, speaker_wav=speaker_wav, **kwargs)
            --> 334 wav = self.tts(
                335     text=text,
                336     speaker=speaker,
                337     language=language,
                338     speaker_wav=speaker_wav,
                339     split_sentences=split_sentences,
                340     **kwargs,
                341 )
                342 self.synthesizer.save_wav(wav=wav, path=file_path, pipe_out=pipe_out)
                343 return file_path

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/api.py:276, in TTS.tts(self, text, speaker, language, speaker_wav, emotion, speed, split_sentences, **kwargs)
                248 """Convert text to speech.
                249 
                250 Args:
               (...)    271         Additional arguments for the model.
                272 """
                273 self._check_arguments(
                274     speaker=speaker, language=language, speaker_wav=speaker_wav, emotion=emotion, speed=speed, **kwargs
                275 )
            --> 276 wav = self.synthesizer.tts(
                277     text=text,
                278     speaker_name=speaker,
                279     language_name=language,
                280     speaker_wav=speaker_wav,
                281     reference_wav=None,
                282     style_wav=None,
                283     style_text=None,
                284     reference_speaker_name=None,
                285     split_sentences=split_sentences,
                286     **kwargs,
                287 )
                288 return wav

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/utils/synthesizer.py:386, in Synthesizer.tts(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)
                384 for sen in sens:
                385 if hasattr(self.tts_model, "synthesize"):
            --> 386         outputs = self.tts_model.synthesize(
                387             text=sen,
                388             config=self.tts_config,
                389             speaker_id=speaker_name,
                390             voice_dirs=self.voice_dir,
                391             d_vector=speaker_embedding,
                392             speaker_wav=speaker_wav,
                393             language=language_name,
                394             **kwargs,
                395         )
                396     else:
                397         # synthesize voice
                398         outputs = synthesis(
                399             model=self.tts_model,
                400             text=sen,
               (...)    408             language_id=language_id,
                409         )

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/models/xtts.py:419, in Xtts.synthesize(self, text, config, speaker_wav, language, speaker_id, **kwargs)
                412     return self.inference(text, language, gpt_cond_latent, speaker_embedding, **settings)
                413 settings.update({
                414     "gpt_cond_len": config.gpt_cond_len,
                415     "gpt_cond_chunk_len": config.gpt_cond_chunk_len,
                416     "max_ref_len": config.max_ref_len,
                417     "sound_norm_refs": config.sound_norm_refs,
                418 })
            --> 419 return self.full_inference(text, speaker_wav, language, **settings)

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)
                113 @functools.wraps(func)
                114 def decorate_context(*args, **kwargs):
                115     with ctx_factory():
            --> 116         return func(*args, **kwargs)

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/models/xtts.py:488, in Xtts.full_inference(self, text, ref_audio_path, language, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, gpt_cond_len, gpt_cond_chunk_len, max_ref_len, sound_norm_refs, **hf_generate_kwargs)
                441 """
                442 This function produces an audio clip of the given text being spoken with the given reference voice.
                443 
               (...)    478     Sample rate is 24kHz.
                479 """
                480 (gpt_cond_latent, speaker_embedding) = self.get_conditioning_latents(
                481     audio_path=ref_audio_path,
                482     gpt_cond_len=gpt_cond_len,
               (...)    485     sound_norm_refs=sound_norm_refs,
                486 )
            --> 488 return self.inference(
                489     text,
                490     language,
                491     gpt_cond_latent,
                492     speaker_embedding,
                493     temperature=temperature,
                494     length_penalty=length_penalty,
                495     repetition_penalty=repetition_penalty,
                496     top_k=top_k,
                497     top_p=top_p,
                498     do_sample=do_sample,
                499     **hf_generate_kwargs,
                500 )

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116, in context_decorator.<locals>.decorate_context(*args, **kwargs)
                113 @functools.wraps(func)
                114 def decorate_context(*args, **kwargs):
                115     with ctx_factory():
            --> 116         return func(*args, **kwargs)

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/models/xtts.py:534, in Xtts.inference(self, text, language, gpt_cond_latent, speaker_embedding, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, num_beams, speed, enable_text_splitting, **hf_generate_kwargs)
                532 for sent in text:
                533     sent = sent.strip().lower()
            --> 534     text_tokens = torch.IntTensor(self.tokenizer.encode(sent, lang=language)).unsqueeze(0).to(self.device)
                536     assert (
                537         text_tokens.shape[-1] < self.args.gpt_max_text_tokens
                538     ), " â— XTTS can only generate text with a maximum of 400 tokens."
                540     with torch.no_grad():

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/layers/xtts/tokenizer.py:649, in VoiceBpeTokenizer.encode(self, txt, lang)
                647 lang = lang.split("-")[0]  # remove the region
                648 self.check_input_length(txt, lang)
            --> 649 txt = self.preprocess_text(txt, lang)
                650 lang = "zh-cn" if lang == "zh" else lang
                651 txt = f"[{lang}]{txt}"

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/layers/xtts/tokenizer.py:638, in VoiceBpeTokenizer.preprocess_text(self, txt, lang)
                636         txt = korean_transliterate(txt)
                637 elif lang == "ja":
            --> 638     txt = japanese_cleaners(txt, self.katsu)
                639 elif lang == "hi":
                640     # @manmay will implement this
                641     txt = basic_cleaners(txt)

            File ~/miniconda3/envs/tts_env/lib/python3.11/functools.py:1001, in cached_property.__get__(self, instance, owner)
                999 val = cache.get(self.attrname, _NOT_FOUND)
               1000 if val is _NOT_FOUND:
            -> 1001     val = self.func(instance)
               1002     try:
               1003         cache[self.attrname] = val

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/TTS/tts/layers/xtts/tokenizer.py:620, in VoiceBpeTokenizer.katsu(self)
                616 @cached_property
                617 def katsu(self):
                618     import cutlet
            --> 620     return cutlet.Cutlet()

            File ~/miniconda3/envs/tts_env/lib/python3.11/site-packages/cutlet/cutlet.py:137, in Cutlet.__init__(self, system, use_foreign_spelling, ensure_ascii, mecab_args)
                134     print("unknown system: {}".format(system))
                135     raise
            --> 137 self.tagger = fugashi.Tagger(mecab_args)
                138 self.exceptions = load_exceptions()
                140 # these are too minor to be worth exposing as arguments

            File fugashi/fugashi.pyx:391, in fugashi.fugashi.Tagger.__init__()

            File fugashi/fugashi.pyx:231, in fugashi.fugashi.GenericTagger.__init__()

            RuntimeError: 
            Failed initializing MeCab. Please see the README for possible solutions:

                https://github.com/polm/fugashi

            If you are still having trouble, please file an issue here, and include the
            ERROR DETAILS below:

                https://github.com/polm/fugashi/issues

            issueã‚’è‹±èªã§æ›¸ãå¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

            ------------------- ERROR DETAILS ------------------------
            arguments: [b'fugashi', b'-C']
            param.cpp(69) [ifs] no such file or directory: /usr/local/etc/mecabrc
            ----------------------------------------------------------
        </code></pre>
    </div>

    <h4>mecabã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            sudo apt-get update
            sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8
        </code></pre>
    </div>

    <h3>generateã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã£ãŸ</h3>
    <p>
        ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã£ãŸéš›ã¯<a href="https://huggingface.co/coqui/XTTS-v2/discussions/122">ã“ã¡ã‚‰ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³</a>ã‚’å‚è€ƒã«ã—ã¦coqui-ttsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã§è§£æ±ºã—ãŸã€‚
    </p>
    <h4>generateã®ã‚¨ãƒ©ãƒ¼</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            An error occurred: 'GPT2InferenceModel' object has no attribute 'generate'
        </code></pre>
    </div>

    <h4>coqui-ttsã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            %pip install coqui-tts transformers==4.35.2
        </code></pre>
    </div>

    <h3>split()ã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã£ãŸ</h3>
    <p>
        ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã£ãŸéš›ã¯splité–¢æ•°ã‚’listå½¢å¼ã®å¤‰æ•°ã«é©ç”¨ã—ã¦ã„ã‚‹ã®ã§ã€stringå½¢å¼ã®å¤‰æ•°ã«é©ç”¨ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ãŸã€‚
    </p>
    <h4>generateã®ã‚¨ãƒ©ãƒ¼</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            An error occurred: 'list' object has no attribute 'strip'
        </code></pre>
    </div>

    <h4>ä¿®æ­£å‰ã®ã‚³ãƒ¼ãƒ‰</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            print("Starting batch processing")

            try:

            Â  Â  with open(text_path, 'r', encoding='utf-8') as f:

            Â  Â  Â  Â  lines = f.readlines()

            Â  Â  Â  Â  total_files = len(lines)

            Â  Â  Â  Â  print(f"Found {total_files} entries in the transcript file.")



            Â  Â  Â  Â  for i, row in enumerate(lines):

            Â  Â  Â  Â  Â  Â  parts = lines.strip().split(':', 1)



            Â  Â  Â  Â  Â  Â  if len(row) != 2:

            Â  Â  Â  Â  Â  Â  Â  Â  print(f"Skipping malformed row: {lines.strip()}")

            Â  Â  Â  Â  Â  Â  Â  Â  continue

            Â  Â  Â  Â  Â  Â  file_id, text_to_synthesize = parts
        </code></pre>
    </div>

    <h4>ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰</h4>
    <div style="position: relative; margin: 1.5rem 0;">
        
        <pre id="pythonCode"><code>
            print("Starting batch processing")
            try:
                with open(text_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_files = len(lines)
                    print(f"Found {total_files} entries in the transcript file.")

                    for i, row in enumerate(lines):
                        # 1. Use .strip() on the 'row' (the string), not 'lines' (the list)
                        clean_row = row.strip()

                        # Skip any empty lines
                        if not clean_row:
                            continue

                        # 2. Split the 'clean_row' string
                        parts = clean_row.split(':', 1)

                        # 3. Check the number of 'parts', not the length of the 'row' string
                        if len(parts) != 2:
                            print(f"Skipping malformed row: {clean_row}")
                            continue

                ...
        </code></pre>
    </div>


    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/10/03</h2>
    <h3>Google Driveã®ãƒã‚¦ãƒ³ãƒˆ</h3>
    <p>
        Google Driveã®ãƒã‚¦ãƒ³ãƒˆã‚’Ubuntuã§è¡Œã†å ´åˆã€å¤šãã®ã‚µã‚¤ãƒˆã§"google-drive-ocamlfuse"ã‚’æ¨å¥¨ã•ã‚Œã‚‹ãŒã€"rclone"ã‚’ä½¿ç”¨ã—ãŸå ´åˆã®ã»ã†ãŒè‰¯ã‹ã£ãŸã€‚å¤§ãã„ã‚µã‚¤ã‚ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰±ã†å ´åˆã«"rclone"ã®ã»ã†ãŒå®‰å®šã—ã¦ã„ã‚‹ã€‚
    </p>
    <h3>cost function(ç›®çš„é–¢æ•°)ã¨ã¯</h3>
    <p>
        cost function(åˆ¥å: loss function, objective function)ã¨ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆã§ã‚ã‚‹ã€‚</br>
        ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã—ãŸå€¤ãŒã©ã‚Œã»ã©æ­£è§£ã‹ã‚‰é›¢ã‚Œã¦ã„ã‚‹ã‹ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã§ã‚ã‚‹ã€‚ã“ã®å€¤ãŒå¤§ãã‘ã‚Œã°å¤§ãã„ã»ã©ãƒ­ã‚¹ãŒå¤šã„ã¨ã„ã†ã“ã¨ã«ãªã‚‹ã€‚</br>
        ç›®çš„é–¢æ•°ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç¨®é¡ãŒã‚ã‚‹ã€‚
    </p>
    <h4>1. å¹³å‡äºŒä¹—èª¤å·®</h4>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$ J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2 $$
    </div>
    <p>ãŸã ã—è¨˜å·ã¯ä»¥ä¸‹ã®é€šã‚Šã«å®šç¾©ã™ã‚‹ã€‚</p>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$ m: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ•° $$<br>
        $$ \hat{y}^{(i)}: iç•ªç›®ã®ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸå€¤ $$<br>
        $$ y^{(i)}: iç•ªç›®ã®ãƒ¢ãƒ‡ãƒ«ã®æ­£è§£ã®å€¤ $$<br>
    </div>
    <p>ç‰¹å¾´</p>
    <ul>
        <li>èª¤å·®ãŒå¤§ãã„å ´åˆã«ã€ãƒšãƒŠãƒ«ãƒ†ã‚£(é–¢æ•°ã®å‡ºåŠ›å€¤)ã‚’å¤§ããã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</li>
        <li>å¤–ã‚Œå€¤ã«å½±éŸ¿ã•ã‚Œã‚„ã™ã„ã€‚</li>
        <li>å¾®åˆ†å¯èƒ½ã§ã‚ã‚‹ãŸã‚ã€å‹¾é…é™ä¸‹æ³•ã§ä½¿ç”¨ã§ãã‚‹ã€‚</li>
    </ul>

    <h4>2. äºŒå€¤äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼</h4>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$ J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(\hat{y}^{(i)}) + (1-y^{(i)}) \log(1-\hat{y}^{(i)})] $$
    </div>
    <p>ç‰¹å¾´</p>
    <ul>
        <li>ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›å€¤ã«å½±éŸ¿ã‚’å¤§ããå—ã‘ã‚‹ã€‚</li>
        <li>äºˆæƒ³ãŒå¤–ã‚Œã¦ã„ã‚‹éš›ã«å‹¾é…ãŒå¼·ãå‡ºã‚‹ã€‚</li>
    </ul>

    <h4>3. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼</h4>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$ [ J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \sum_{j=1}^{C} y_j^{(i)} \log(\hat{y}_j^{(i)}) $$
    </div>
    <div style="text-align: center; margin: 1.5rem 0;">
        $$ C: ã‚¯ãƒ©ã‚¹ã®æ•° $$
    </div>




    </section>

    <?php renderAdBanner(); ?>

    <section>
    <h2>2025/10/15</h2>
    </section>

    <?php renderAdBanner(); ?>

    
    <footer style="margin-top: 3rem; padding-top: 1rem; border-top: 1px solid #ddd; text-align: center; color: #666;">
        <p>&copy; <?php echo date('Y'); ?> éŸ³å£°ç ”ç©¶ãƒãƒ¼ãƒˆ - æœ€çµ‚æ›´æ–°: <?php echo date('Yå¹´mæœˆdæ—¥ H:i', filemtime(__FILE__)); ?></p>
    </footer>
  </article>
</main>

<?php renderFooter(); ?>

<!-- æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨˜äº‹ï¼‰ -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "éŸ³å£°è§£æã¨æ©Ÿæ¢°å­¦ç¿’ã®ç ”ç©¶ãƒ¡ãƒ¢",
  "description": "<?php echo htmlspecialchars($description, ENT_QUOTES, 'UTF-8'); ?>",
  "author": {
    "@type": "Organization",
    "name": "ãƒ¡ãƒ¢å¸³"
  },
  "datePublished": "2025-09-09",
  "dateModified": "<?php echo date('c', filemtime(__FILE__)); ?>",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://memo-site.com/speech.php"
  },
  "about": [
    {
      "@type": "Thing",
      "name": "éŸ³å£°è§£æ"
    },
    {
      "@type": "Thing", 
      "name": "æ©Ÿæ¢°å­¦ç¿’"
    },
    {
      "@type": "Thing",
      "name": "MFCC"
    },
    {
      "@type": "Thing",
      "name": "Python"
    }
  ],
  "keywords": ["éŸ³å£°è§£æ", "æ©Ÿæ¢°å­¦ç¿’", "MFCC", "DTW", "z-score", "Python", "ã‚¢ã‚¤ãƒŒèª"]
}
</script>

<!-- ãƒ‘ãƒ³ããšãƒªã‚¹ãƒˆ -->
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "ãƒ›ãƒ¼ãƒ ",
      "item": "https://memo-site.com/"
    },
    {
      "@type": "ListItem",
      "position": 2,
      "name": "éŸ³å£°è§£æ",
      "item": "https://memo-site.com/speech.php"
    }
  ]
}
</script>